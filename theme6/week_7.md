# Week 7

## Reference 1: Responsible Research and Innovation (RRI) Richard Owen
负责开发工具的项目研究和创新作为整个欧洲的系统方法.

下一代的未来就是我们的现在. 我们正在创造未来, 科学和创新是其中的一部分.

对于负责任的创新, 我们首先要说的是, 它意味着人们认识到科学和创新的变革力量, 创造未来. 

它鼓励我们思考我们希望科学和创新创造什么样的未来.

第二件事是创新结合了社会, 政治和伦理问题.  也就是扩大并蕴含科学技术的创新的 伦理, 社会, 环境问题以及政治问题, 而不是在特定未来的某个时间.

第三件意识到的事: 存在一定的不确定性, 我们无法在初始阶段轻易预测创新的结果和效果. 我们也不能轻易划定责任界限, 并说创新的效果和影响从什么时候开始. 因此必须回答在不确定性面前继续工作的问题, 无知和歧义. 

RRI的概念基本上回答了我们希望科学和创新创造什么样的未来的问题, 以及我们如何与所有相关人员做到这一点. 

研究和创新必须具有包容性, 包括对创新目标和过程的看法, 并应包括多样性. 第二这个过程必须是初步和反思性的. 必须问科学和创新能够带来什么样的未来. 第三公开透明, 这非常重要, 但非常困难尤其是在私营部门, 承诺开放获取成果, 透明度, 研究诚信. 如果我们对这种变化作出反应就会带来真正的变化, 一种认知的过程. 

必须有一些规范性约束力, 将负责任的创新作为一个过程, 这与我们作为一个社会的价值观有关. 我们希望研究和创新与哪些价值观相结合成为创造未来的过程. 根本上说这是对可持续发展, 隐私, 道德的承诺.

## Reference 2: How to Apply RRI
您的用户有特定的需求, 你一定要回应人们的期望! 现在你的生意做大, 你的客户关心医疗数据的隐私, 产品安全, 以及对待员工方式.

绝大多数消费者都认为科学技术的发展可能过快地改变他们的生活, 并对健康和环境产生负面影响, 社会和环境影响日益复杂. 企业需要新的方法来管理这个问题, 需要证明您对道德社会和环境负责. 从原型设计到市场发布的每个步骤都需要消费者的参与, 您的组织可以实施企业社会责任原则确保健康和多元化的工作场所, 您的组织可以利用工作来帮助您预见未来风险, 同时分析生产线, 产品和服务对环境, 社会或健康的影响. 您的组织应寻求遵守合格的规范和标准. 这些要素构成了公共研究管理框架的一部分, 旨在使研究和创新活动更加负责任. 

与消费者及其家人的良好沟通可以开发出符合他们需求和期望的产品同时确保其适销性, 当谈到开发技术来改善他们的生活时他们需要信任您.

RRI是一个公共/政府支持的框架, 将为您和您的用户提供更多确定性. 

## Reference 3: \
pdf 过  太多了 T^T

## Reference 4: B Stahl - RRI Discourse into Private Domain
pdf

## Reference 5: Michael Kearns & Aaron Roth: The Ethical Algorithm
现在用机器学习开始做一些重要任务: 贷款决策, 人力资源招聘, 监狱保释... 人们担心这些算法可能违反 我们对人类决策者 在做出这些决策时所期望的一些社会规范这是很自然的, 事实上有很多证据表明这种情况确实发生了. 

算法本事是工具可以用来做好 / 坏事. 所以要监管!!!

很难理解如此庞大数据中包含的所有信息. 所以你使用数据集来制定一些通常较窄的目标函数, 一些分类误差或者利润的代理; 之后使用某种工具比如随机梯度下降来搜寻大量模型, 以找到最合适或非常擅长最大化狭窄目标函数的模型, 如果这个模型在实践中伤害了某些人, 这种伤害可能并不是开发者某种恶意的结果. 而是模型的未料到和无意的副作用.

如何将我们的社会价值观或者不希望算法展示出来的行为嵌入到设计过程本身中. 

隐私, 公平, 可追责, 可解释, 道德.

多个掩盖隐私不彻底的数据库进行三角测量就有可能得到有关人的相关信息. 

隐私的真正定义如果严格遵守, 那我们可能不能拿数据做任何有趣事情. 专家的定义是包含您的数据数据分析的结果不应该对您造成任何形式的伤害. 

差异隐私的概念: 说明您的数据并不是本次分析中关键的缺失部分, 一个分析包括你一个不包括你, 结果一样. 这是算法的属性, 不是关于特定数据集的数据, 通过在计算中添加噪声来实现的, 您可以从确定性算法转向随机算法.

这依然很难, 但好消息: 现代统计或ML了解到的几乎所有技术都有一个变体. 可以提供差异隐私. 

不同群体带来的数据一定会造成结果的不公平, 拟合的线往下移可能会对群体A不公平, 往上移可能会对群体B不公平. 需要更多努力.

地图的导航类似纳什均衡, 显示某条道这样走用时最短, 如果所有的人都这么走会发生什么? "竞争平衡"

算法决策系统的流行所引起的道德问题的解决方法本身应该在很大程度上是算法性的?
算法不能解决所有的问题, 法律法规和更传统的解决方案仍然有很大的空间和重要性, 真正棘手的问题仍然是社会性的. 解决方法不能仅仅通过考虑一些范围非常狭窄的算法而得出, 而不考虑他们所生活的更广泛的社会和算法生态系统. 

## 课上想到的:
在一些严格措施下, 可能不会造成一些直接影响, 但比如机器学习, 会造成一些不直接的负面影响, 这可能不是开发者的初衷, 这不能怪开发者, 应该有一套通用的结构去指导技术的道德规范.

## Reference 6: 



